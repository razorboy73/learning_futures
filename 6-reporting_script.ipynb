{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f618bc04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\farty\\AppData\\Local\\Temp\\ipykernel_68140\\1160959573.py:412: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  eq_m = eq.resample(\"M\").last()\n",
      "C:\\Users\\farty\\AppData\\Local\\Temp\\ipykernel_68140\\1160959573.py:414: FutureWarning: 'Y' is deprecated and will be removed in a future version, please use 'YE' instead.\n",
      "  eq_y = eq.resample(\"Y\").last()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report outputs written to: C:\\TWS API\\source\\pythonclient\\TradingIdeas\\Futures\\06-reporting\n",
      "- daily_account_ledger.csv, daily_account_ledger.parquet\n",
      "- trade_impact_ledger.csv\n",
      "- rolling_annualized_volatility.csv, rolling_annualized_volatility.parquet\n",
      "- performance_summary.csv, monthly_returns.csv, yearly_returns.csv, yearly_drawdowns.csv\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import os\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.lib.units import inch\n",
    "from reportlab.pdfgen import canvas\n",
    "\n",
    "\"\"\"\n",
    "===============================================================================\n",
    "BACKTEST PERFORMANCE REPORT + TRADE / CASH / MARGIN / EQUITY IMPACT LEDGERS\n",
    "ENHANCED WITH YEARLY DRAWDOWN ANALYSIS\n",
    "===============================================================================\n",
    "\n",
    "Inputs expected in BACKTEST_OUTPUT_ROOT:\n",
    "- portfolio_equity.(csv|parquet)  [required]\n",
    "- positions.(csv|parquet)         [required for margin/free cash]\n",
    "- trades.csv                      [optional but recommended]\n",
    "\n",
    "Also reads contract margins from:\n",
    "- futures_contracts_full.parquet  [required for margin/free cash]\n",
    "\n",
    "Outputs in REPORT_ROOT:\n",
    "- performance_summary.csv          [includes overall max drawdown]\n",
    "- monthly_returns.csv, yearly_returns.csv\n",
    "- yearly_drawdowns.csv             [NEW: max drawdown per year]\n",
    "- rolling_annualized_volatility.(csv|parquet)\n",
    "- daily_account_ledger.(csv|parquet)\n",
    "- trade_impact_ledger.csv\n",
    "- charts (png), report.md, report.pdf\n",
    "\n",
    "NEW FEATURES:\n",
    "1. Maximum drawdown for entire strategy (already in performance_summary.csv)\n",
    "2. Maximum drawdown per calendar year (new file: yearly_drawdowns.csv)\n",
    "===============================================================================\n",
    "\"\"\"\n",
    "\n",
    "# ============================================================\n",
    "# Configuration\n",
    "# ============================================================\n",
    "\n",
    "CONFIG = {\n",
    "    \"backtest_output_root\": Path(\"./05-futures_backtest_position_sizing_mapped\"),\n",
    "    \"report_root\": Path(\"./06-reporting\"),\n",
    "\n",
    "    # Universe / contract specs for margin lookup\n",
    "    \"contracts_file\": Path(\"./01-futures_universe/futures_contracts_full.parquet\"),\n",
    "\n",
    "    # Annualization\n",
    "    \"trading_days_per_year\": 256,\n",
    "\n",
    "    # Rolling windows for plots\n",
    "    \"rolling_vol_window\": 32,\n",
    "\n",
    "    # Charts / outputs\n",
    "    \"write_pdf\": True,\n",
    "    \"write_markdown\": True,\n",
    "    \"write_charts\": True,\n",
    "\n",
    "    # Margin column auto-detection candidates (first match wins)\n",
    "    \"margin_column_candidates\": [\n",
    "        \"initial_margin\",\n",
    "        \"init_margin\",\n",
    "        \"margin\",\n",
    "        \"initial_margin_usd\",\n",
    "        \"margin_usd\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "# ============================================================\n",
    "# Data loading\n",
    "# ============================================================\n",
    "\n",
    "def _load_df_prefer_parquet(root: Path, stem: str) -> pd.DataFrame:\n",
    "    pq = root / f\"{stem}.parquet\"\n",
    "    csv = root / f\"{stem}.csv\"\n",
    "    if pq.exists():\n",
    "        return pd.read_parquet(pq)\n",
    "    if csv.exists():\n",
    "        return pd.read_csv(csv)\n",
    "    raise FileNotFoundError(f\"Missing {stem}.parquet or {stem}.csv in {root}\")\n",
    "\n",
    "def load_inputs(root: Path):\n",
    "    portfolio = _load_df_prefer_parquet(root, \"portfolio_equity\")\n",
    "\n",
    "    positions = None\n",
    "    try:\n",
    "        positions = _load_df_prefer_parquet(root, \"positions\")\n",
    "    except Exception:\n",
    "        positions = None\n",
    "\n",
    "    trades = None\n",
    "    trades_path = root / \"trades.csv\"\n",
    "    if trades_path.exists():\n",
    "        trades = pd.read_csv(trades_path)\n",
    "\n",
    "    return portfolio, positions, trades\n",
    "\n",
    "def normalize_portfolio_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df.columns = [str(c).strip().lower() for c in df.columns]\n",
    "\n",
    "    if \"date\" not in df.columns or \"equity\" not in df.columns:\n",
    "        raise ValueError(f\"portfolio_equity must include date and equity. Columns: {list(df.columns)}\")\n",
    "\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"], errors=\"coerce\")\n",
    "    df = df.dropna(subset=[\"date\"]).sort_values(\"date\")\n",
    "\n",
    "    df[\"equity\"] = pd.to_numeric(df[\"equity\"], errors=\"coerce\")\n",
    "    df = df.dropna(subset=[\"equity\"])\n",
    "\n",
    "    if \"return\" not in df.columns:\n",
    "        df[\"return\"] = df[\"equity\"].pct_change()\n",
    "    df[\"return\"] = pd.to_numeric(df[\"return\"], errors=\"coerce\")\n",
    "\n",
    "    # Optional columns (if present from your engine)\n",
    "    for col in [\"pnl\", \"commissions\", \"k_active\", \"tau_per_instrument\"]:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "def normalize_positions_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    if df is None or df.empty:\n",
    "        return None\n",
    "    df = df.copy()\n",
    "    df.columns = [str(c).strip() for c in df.columns]\n",
    "    if \"date\" not in [c.lower() for c in df.columns]:\n",
    "        raise ValueError(\"positions must include a date column\")\n",
    "    # standardize date col name to 'date'\n",
    "    date_col = next(c for c in df.columns if c.lower() == \"date\")\n",
    "    if date_col != \"date\":\n",
    "        df = df.rename(columns={date_col: \"date\"})\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"], errors=\"coerce\")\n",
    "    df = df.dropna(subset=[\"date\"]).sort_values(\"date\")\n",
    "    # coerce positions to numeric ints (contracts)\n",
    "    for c in df.columns:\n",
    "        if c == \"date\":\n",
    "            continue\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\").fillna(0.0)\n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "def normalize_trades_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    if df is None or df.empty:\n",
    "        return None\n",
    "    df = df.copy()\n",
    "    df.columns = [str(c).strip().lower() for c in df.columns]\n",
    "    if \"date\" in df.columns:\n",
    "        df[\"date\"] = pd.to_datetime(df[\"date\"], errors=\"coerce\")\n",
    "    for col in [\"commission\", \"delta_contracts\", \"new_contracts\", \"prev_contracts\"]:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "    return df\n",
    "\n",
    "# ============================================================\n",
    "# Margin lookup\n",
    "# ============================================================\n",
    "\n",
    "def load_margin_map(contracts_file: Path, candidates: list[str]) -> dict:\n",
    "    if not contracts_file.exists():\n",
    "        raise FileNotFoundError(f\"contracts_file not found: {contracts_file}\")\n",
    "\n",
    "    df = pd.read_parquet(contracts_file)\n",
    "    df.columns = [str(c).strip().lower() for c in df.columns]\n",
    "\n",
    "    sym_col_candidates = [\"symbol\", \"ticker\", \"root\", \"contract\", \"instrument\"]\n",
    "    sym_col = next((c for c in sym_col_candidates if c in df.columns), None)\n",
    "    if sym_col is None:\n",
    "        raise ValueError(f\"Could not find symbol column in contracts file. Columns: {list(df.columns)}\")\n",
    "\n",
    "    margin_col = next((c for c in candidates if c in df.columns), None)\n",
    "    if margin_col is None:\n",
    "        # No margin in file; caller can still run, but margin_used will be NaN\n",
    "        return {}\n",
    "\n",
    "    out = {}\n",
    "    for _, r in df.iterrows():\n",
    "        sym = str(r[sym_col]).strip().upper()\n",
    "        m = pd.to_numeric(r[margin_col], errors=\"coerce\")\n",
    "        if sym and pd.notna(m) and float(m) > 0:\n",
    "            out[sym] = float(m)\n",
    "    return out\n",
    "\n",
    "# ============================================================\n",
    "# Ledgers\n",
    "# ============================================================\n",
    "\n",
    "def compute_daily_margin_used(positions: pd.DataFrame, margin_map: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    positions: columns: date, <TRADE_SYMBOL_1>, <TRADE_SYMBOL_2>, ...\n",
    "    margin_used_t = sum_i abs(contracts_i,t) * margin_per_contract_i\n",
    "    \"\"\"\n",
    "    if positions is None or positions.empty:\n",
    "        return None\n",
    "\n",
    "    pos = positions.copy()\n",
    "    syms = [c for c in pos.columns if c != \"date\"]\n",
    "    # margin vector aligned to columns (NaN if missing)\n",
    "    m = np.array([margin_map.get(s.upper(), np.nan) for s in syms], dtype=float)\n",
    "\n",
    "    # abs positions matrix\n",
    "    mat = pos[syms].to_numpy(dtype=float)\n",
    "    abs_mat = np.abs(mat)\n",
    "\n",
    "    # margin used per day\n",
    "    # if margin missing for any symbol, result becomes NaN; handle by treating missing margin as 0 if you prefer\n",
    "    margin_used = np.nansum(abs_mat * m, axis=1)\n",
    "\n",
    "    out = pd.DataFrame({\n",
    "        \"date\": pos[\"date\"],\n",
    "        \"margin_used\": margin_used,\n",
    "    })\n",
    "    return out\n",
    "\n",
    "def build_daily_account_ledger(portfolio: pd.DataFrame, positions: pd.DataFrame, margin_map: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Daily account statement:\n",
    "    - equity (from portfolio)\n",
    "    - pnl, commissions (from portfolio if present)\n",
    "    - margin_used (from positions * margin_map)\n",
    "    - free_cash = equity - margin_used\n",
    "    - cash_before_trades = equity_prev + pnl_today\n",
    "    - cash_after_trades = cash_before_trades - commissions_today\n",
    "    \"\"\"\n",
    "    p = portfolio.copy()\n",
    "    p = p.sort_values(\"date\").reset_index(drop=True)\n",
    "\n",
    "    # Margin\n",
    "    if positions is not None and margin_map:\n",
    "        m = compute_daily_margin_used(positions, margin_map)\n",
    "        p = p.merge(m, on=\"date\", how=\"left\")\n",
    "    else:\n",
    "        p[\"margin_used\"] = np.nan\n",
    "\n",
    "    p[\"free_cash\"] = p[\"equity\"] - p[\"margin_used\"]\n",
    "\n",
    "    # Cash lens (futures-style): equity is your account value; trades consume commissions; margin is a requirement\n",
    "    pnl_col = \"pnl\" if \"pnl\" in p.columns else None\n",
    "    comm_col = \"commissions\" if \"commissions\" in p.columns else None\n",
    "\n",
    "    p[\"equity_prev\"] = p[\"equity\"].shift(1)\n",
    "\n",
    "    if pnl_col is not None:\n",
    "        p[\"cash_before_trades\"] = p[\"equity_prev\"] + p[pnl_col]\n",
    "    else:\n",
    "        # fallback: approximate using equity change (less commissions unknown)\n",
    "        p[\"cash_before_trades\"] = p[\"equity_prev\"]\n",
    "\n",
    "    if comm_col is not None:\n",
    "        p[\"cash_after_trades\"] = p[\"cash_before_trades\"] - p[comm_col]\n",
    "    else:\n",
    "        p[\"cash_after_trades\"] = p[\"cash_before_trades\"]\n",
    "\n",
    "    # free cash before/after\n",
    "    p[\"margin_used_prev\"] = p[\"margin_used\"].shift(1)\n",
    "    p[\"free_cash_prev\"] = p[\"equity_prev\"] - p[\"margin_used_prev\"]\n",
    "    p[\"free_cash_after_trades\"] = p[\"cash_after_trades\"] - p[\"margin_used\"]\n",
    "\n",
    "    # tidy\n",
    "    cols = [\n",
    "        \"date\", \"equity\", \"return\",\n",
    "        \"pnl\" if \"pnl\" in p.columns else None,\n",
    "        \"commissions\" if \"commissions\" in p.columns else None,\n",
    "        \"margin_used\", \"free_cash\",\n",
    "        \"cash_before_trades\", \"cash_after_trades\",\n",
    "        \"free_cash_prev\", \"free_cash_after_trades\",\n",
    "        \"k_active\" if \"k_active\" in p.columns else None,\n",
    "        \"tau_per_instrument\" if \"tau_per_instrument\" in p.columns else None,\n",
    "    ]\n",
    "    cols = [c for c in cols if c is not None and c in p.columns]\n",
    "    return p[cols].copy()\n",
    "\n",
    "def build_trade_impact_ledger(trades: pd.DataFrame, daily_ledger: pd.DataFrame, positions: pd.DataFrame, margin_map: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    For each trade row, attach:\n",
    "    - equity_before (prior day end), equity_after (same-day end)\n",
    "    - cash_before_trades, cash_after_trades\n",
    "    - margin_before (prior day), margin_after (same day)\n",
    "    - free_cash_before, free_cash_after\n",
    "    \"\"\"\n",
    "    if trades is None or trades.empty:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    t = trades.copy()\n",
    "    # Try to use trade_symbol if present, else symbol\n",
    "    sym_col = \"trade_symbol\" if \"trade_symbol\" in t.columns else (\"symbol\" if \"symbol\" in t.columns else None)\n",
    "    if sym_col is None:\n",
    "        sym_col = \"trade_symbol\"\n",
    "        t[sym_col] = \"\"\n",
    "\n",
    "    # Merge daily ledger (after trades)\n",
    "    d = daily_ledger.copy()\n",
    "    dcols = [\"date\", \"equity\", \"margin_used\", \"free_cash\", \"cash_before_trades\", \"cash_after_trades\", \"free_cash_prev\", \"free_cash_after_trades\"]\n",
    "    dcols = [c for c in dcols if c in d.columns]\n",
    "    t = t.merge(d[dcols], on=\"date\", how=\"left\")\n",
    "\n",
    "    # Add before/after equity explicitly\n",
    "    # equity_before = prior ledger equity (date-1)\n",
    "    d_before = daily_ledger[[\"date\", \"equity\", \"margin_used\", \"free_cash\"]].copy()\n",
    "    d_before = d_before.rename(columns={\n",
    "        \"equity\": \"equity_before\",\n",
    "        \"margin_used\": \"margin_before\",\n",
    "        \"free_cash\": \"free_cash_before\",\n",
    "    })\n",
    "    d_before[\"date\"] = pd.to_datetime(d_before[\"date\"])\n",
    "    d_before[\"date_next\"] = d_before[\"date\"].shift(-1)  # not used\n",
    "    # Better: merge by prior day using shift on ledger\n",
    "    shifted = daily_ledger.copy()\n",
    "    shifted[\"date\"] = pd.to_datetime(shifted[\"date\"])\n",
    "    shifted = shifted.sort_values(\"date\").reset_index(drop=True)\n",
    "    shifted[\"equity_before\"] = shifted[\"equity\"].shift(1)\n",
    "    shifted[\"margin_before\"] = shifted[\"margin_used\"].shift(1)\n",
    "    shifted[\"free_cash_before\"] = shifted[\"free_cash\"].shift(1)\n",
    "    shifted = shifted[[\"date\", \"equity_before\", \"margin_before\", \"free_cash_before\"]]\n",
    "    t = t.merge(shifted, on=\"date\", how=\"left\")\n",
    "\n",
    "    # equity_after etc already in merged columns\n",
    "    t = t.rename(columns={\n",
    "        \"equity\": \"equity_after\",\n",
    "        \"margin_used\": \"margin_after\",\n",
    "        \"free_cash\": \"free_cash_after\",\n",
    "    })\n",
    "\n",
    "    # Commission column normalization\n",
    "    if \"commission\" in t.columns:\n",
    "        t[\"commission\"] = pd.to_numeric(t[\"commission\"], errors=\"coerce\").fillna(0.0)\n",
    "\n",
    "    # A simple \"trade_day\" flag\n",
    "    t[\"is_trade_day\"] = True\n",
    "\n",
    "    # Sort for readability\n",
    "    sort_cols = [\"date\"]\n",
    "    if sym_col in t.columns:\n",
    "        sort_cols.append(sym_col)\n",
    "    return t.sort_values(sort_cols).reset_index(drop=True)\n",
    "\n",
    "# ============================================================\n",
    "# Core metrics & tables (existing)\n",
    "# ============================================================\n",
    "\n",
    "def compute_drawdown(equity: pd.Series) -> pd.Series:\n",
    "    running_max = equity.cummax()\n",
    "    return equity / running_max - 1.0\n",
    "\n",
    "def compute_rolling_annualized_volatility(portfolio: pd.DataFrame, window_days: int = 42) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute 2-month rolling annualized standard deviation of percentage returns.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    portfolio : DataFrame with 'date' and 'return' columns\n",
    "    window_days : rolling window in trading days (default 42 â‰ˆ 2 months)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    DataFrame with columns: date, rolling_ann_vol\n",
    "    \"\"\"\n",
    "    df = portfolio[[\"date\", \"return\"]].copy()\n",
    "    df = df.sort_values(\"date\").reset_index(drop=True)\n",
    "    \n",
    "    trading_days_per_year = CONFIG[\"trading_days_per_year\"]\n",
    "    \n",
    "    # Rolling std of daily returns, annualized\n",
    "    rolling_std = df[\"return\"].rolling(window=window_days, min_periods=window_days).std()\n",
    "    df[\"rolling_ann_vol\"] = rolling_std * np.sqrt(trading_days_per_year)\n",
    "    \n",
    "    return df[[\"date\", \"rolling_ann_vol\"]].copy()\n",
    "\n",
    "\n",
    "def compute_performance_metrics(portfolio: pd.DataFrame, trading_days_per_year: int) -> dict:\n",
    "    equity = portfolio[\"equity\"].astype(float).reset_index(drop=True)\n",
    "    rets = portfolio[\"return\"].astype(float).reset_index(drop=True).dropna()\n",
    "    n_days = int(rets.shape[0])\n",
    "\n",
    "    start_eq = float(equity.iloc[0])\n",
    "    end_eq = float(equity.iloc[-1])\n",
    "    total_return = end_eq / start_eq - 1.0\n",
    "\n",
    "    years = n_days / float(trading_days_per_year) if n_days > 0 else np.nan\n",
    "    cagr = (end_eq / start_eq) ** (1.0 / years) - 1.0 if (years and years > 0) else np.nan\n",
    "\n",
    "    mean_daily = float(rets.mean()) if n_days > 0 else np.nan\n",
    "    std_daily = float(rets.std(ddof=1)) if n_days > 1 else np.nan\n",
    "\n",
    "    ann_vol = std_daily * np.sqrt(trading_days_per_year) if np.isfinite(std_daily) else np.nan\n",
    "    sharpe = (mean_daily / std_daily) * np.sqrt(trading_days_per_year) if (std_daily and std_daily > 0) else np.nan\n",
    "\n",
    "    dd = compute_drawdown(equity)\n",
    "    max_dd = float(dd.min()) if len(dd) else np.nan\n",
    "\n",
    "    return {\n",
    "        \"start_date\": portfolio[\"date\"].iloc[0].date().isoformat(),\n",
    "        \"end_date\": portfolio[\"date\"].iloc[-1].date().isoformat(),\n",
    "        \"trading_days\": n_days,\n",
    "        \"start_equity\": start_eq,\n",
    "        \"end_equity\": end_eq,\n",
    "        \"total_return\": total_return,\n",
    "        \"cagr\": cagr,\n",
    "        \"ann_vol\": ann_vol,\n",
    "        \"sharpe\": sharpe,\n",
    "        \"max_drawdown\": max_dd,\n",
    "    }\n",
    "\n",
    "def monthly_and_yearly_returns(portfolio: pd.DataFrame):\n",
    "    df = portfolio.copy().set_index(\"date\")\n",
    "    eq = df[\"equity\"].astype(float)\n",
    "    eq_m = eq.resample(\"M\").last()\n",
    "    ret_m = eq_m.pct_change()\n",
    "    eq_y = eq.resample(\"Y\").last()\n",
    "    ret_y = eq_y.pct_change()\n",
    "\n",
    "    monthly_tbl = ret_m.to_frame(\"ret\")\n",
    "    monthly_tbl[\"year\"] = monthly_tbl.index.year\n",
    "    monthly_tbl[\"month\"] = monthly_tbl.index.month\n",
    "    monthly_pivot = monthly_tbl.pivot(index=\"year\", columns=\"month\", values=\"ret\").sort_index()\n",
    "\n",
    "    yearly = ret_y.to_frame(\"yearly_return\")\n",
    "    yearly.index = yearly.index.year\n",
    "    return monthly_pivot, yearly\n",
    "\n",
    "def compute_yearly_drawdowns(portfolio: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute maximum drawdown for each calendar year.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    portfolio : DataFrame with 'date' and 'equity' columns\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    DataFrame with columns: year, max_drawdown\n",
    "    \"\"\"\n",
    "    df = portfolio.copy()\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df = df.sort_values('date').reset_index(drop=True)\n",
    "    df['year'] = df['date'].dt.year\n",
    "    \n",
    "    yearly_dd = []\n",
    "    \n",
    "    for year in df['year'].unique():\n",
    "        year_data = df[df['year'] == year].copy()\n",
    "        if len(year_data) > 0:\n",
    "            equity = year_data['equity'].astype(float)\n",
    "            dd = compute_drawdown(equity)\n",
    "            max_dd = float(dd.min()) if len(dd) > 0 else np.nan\n",
    "            yearly_dd.append({\n",
    "                'year': int(year),\n",
    "                'max_drawdown': max_dd\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(yearly_dd)\n",
    "\n",
    "def compute_yearly_risk_metrics(portfolio: pd.DataFrame, trading_days_per_year: int = 256) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute annual risk-adjusted metrics for each calendar year:\n",
    "    - Annual standard deviation (volatility)\n",
    "    - Sharpe ratio\n",
    "    - Calmar ratio (annual return / abs(max drawdown))\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    portfolio : DataFrame with 'date', 'equity', and 'return' columns\n",
    "    trading_days_per_year : int, default 256\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    DataFrame with columns: year, annual_std_dev, sharpe_ratio, calmar_ratio\n",
    "    \"\"\"\n",
    "    df = portfolio.copy()\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df = df.sort_values('date').reset_index(drop=True)\n",
    "    df['year'] = df['date'].dt.year\n",
    "    \n",
    "    yearly_metrics = []\n",
    "    \n",
    "    for year in df['year'].unique():\n",
    "        year_data = df[df['year'] == year].copy()\n",
    "        \n",
    "        if len(year_data) < 2:\n",
    "            # Not enough data for this year\n",
    "            yearly_metrics.append({\n",
    "                'year': int(year),\n",
    "                'annual_std_dev': np.nan,\n",
    "                'sharpe_ratio': np.nan,\n",
    "                'calmar_ratio': np.nan,\n",
    "            })\n",
    "            continue\n",
    "        \n",
    "        # Get returns and equity for the year\n",
    "        returns = year_data['return'].dropna()\n",
    "        equity = year_data['equity'].astype(float)\n",
    "        \n",
    "        if len(returns) < 2:\n",
    "            yearly_metrics.append({\n",
    "                'year': int(year),\n",
    "                'annual_std_dev': np.nan,\n",
    "                'sharpe_ratio': np.nan,\n",
    "                'calmar_ratio': np.nan,\n",
    "            })\n",
    "            continue\n",
    "        \n",
    "        # Calculate daily statistics\n",
    "        mean_daily = float(returns.mean())\n",
    "        std_daily = float(returns.std(ddof=1))\n",
    "        n_days = len(returns)\n",
    "        \n",
    "        # Annualize standard deviation\n",
    "        annual_std_dev = std_daily * np.sqrt(trading_days_per_year) if np.isfinite(std_daily) else np.nan\n",
    "        \n",
    "        # Calculate Sharpe ratio (annualized)\n",
    "        sharpe = (mean_daily / std_daily) * np.sqrt(trading_days_per_year) if (std_daily and std_daily > 0) else np.nan\n",
    "        \n",
    "        # Calculate annual return for this year\n",
    "        start_equity = equity.iloc[0]\n",
    "        end_equity = equity.iloc[-1]\n",
    "        annual_return = (end_equity / start_equity) ** (trading_days_per_year / n_days) - 1.0 if n_days > 0 else np.nan\n",
    "        \n",
    "        # Calculate max drawdown for the year\n",
    "        running_max = equity.cummax()\n",
    "        drawdown = equity / running_max - 1.0\n",
    "        max_dd = float(drawdown.min()) if len(drawdown) > 0 else np.nan\n",
    "        \n",
    "        # Calculate Calmar ratio (annual return / abs(max drawdown))\n",
    "        calmar = annual_return / abs(max_dd) if (np.isfinite(max_dd) and max_dd != 0) else np.nan\n",
    "        \n",
    "        yearly_metrics.append({\n",
    "            'year': int(year),\n",
    "            'annual_std_dev': annual_std_dev,\n",
    "            'sharpe_ratio': sharpe,\n",
    "            'calmar_ratio': calmar,\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(yearly_metrics)\n",
    "\n",
    "# ============================================================\n",
    "# Charts (trade markers)\n",
    "# ============================================================\n",
    "\n",
    "def save_equity_curve_with_trade_markers(portfolio: pd.DataFrame, trades: pd.DataFrame, out_png: Path):\n",
    "    df = portfolio.copy()\n",
    "    plt.figure()\n",
    "    plt.plot(df[\"date\"], df[\"equity\"])\n",
    "    if trades is not None and not trades.empty and \"date\" in trades.columns:\n",
    "        td = pd.to_datetime(trades[\"date\"], errors=\"coerce\").dropna().drop_duplicates().sort_values()\n",
    "        for d in td:\n",
    "            plt.axvline(d, linewidth=0.5)\n",
    "    plt.title(\"Equity Curve (Trade Days Marked)\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Equity\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_png, dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "def save_margin_and_free_cash(daily_ledger: pd.DataFrame, out_png: Path):\n",
    "    plt.figure()\n",
    "    plt.plot(daily_ledger[\"date\"], daily_ledger[\"margin_used\"])\n",
    "    plt.title(\"Margin Used\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Margin Used\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_png, dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "    # free cash\n",
    "    out_png2 = out_png.with_name(\"free_cash.png\")\n",
    "    plt.figure()\n",
    "    plt.plot(daily_ledger[\"date\"], daily_ledger[\"free_cash\"])\n",
    "    plt.title(\"Free Cash (Equity - Margin)\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Free Cash\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_png2, dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "# ============================================================\n",
    "# Main\n",
    "# ============================================================\n",
    "\n",
    "def main():\n",
    "    root = CONFIG[\"backtest_output_root\"]\n",
    "    report_root = CONFIG[\"report_root\"]\n",
    "    report_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    portfolio_df, positions_df, trades_df = load_inputs(root)\n",
    "    portfolio_df = normalize_portfolio_df(portfolio_df)\n",
    "    positions_df = normalize_positions_df(positions_df)\n",
    "    trades_df = normalize_trades_df(trades_df)\n",
    "\n",
    "    # Margin map\n",
    "    margin_map = load_margin_map(CONFIG[\"contracts_file\"], CONFIG[\"margin_column_candidates\"])\n",
    "\n",
    "    # Build ledgers\n",
    "    daily_ledger = build_daily_account_ledger(portfolio_df, positions_df, margin_map)\n",
    "    trade_impact = build_trade_impact_ledger(trades_df, daily_ledger, positions_df, margin_map)\n",
    "\n",
    "    # Write ledgers\n",
    "    daily_csv = report_root / \"daily_account_ledger.csv\"\n",
    "    daily_pq = report_root / \"daily_account_ledger.parquet\"\n",
    "    daily_ledger.to_csv(daily_csv, index=False)\n",
    "    daily_ledger.to_parquet(daily_pq, index=False, compression=\"snappy\")\n",
    "\n",
    "    trade_csv = report_root / \"trade_impact_ledger.csv\"\n",
    "    trade_impact.to_csv(trade_csv, index=False)\n",
    "    \n",
    "    # Compute and save rolling volatility\n",
    "    rolling_vol_df = compute_rolling_annualized_volatility(portfolio_df, window_days=42)\n",
    "    rolling_vol_csv = report_root / \"rolling_annualized_volatility.csv\"\n",
    "    rolling_vol_pq = report_root / \"rolling_annualized_volatility.parquet\"\n",
    "    rolling_vol_df.to_csv(rolling_vol_csv, index=False)\n",
    "    rolling_vol_df.to_parquet(rolling_vol_pq, index=False, compression=\"snappy\")\n",
    "\n",
    "\n",
    "    # Existing summary outputs\n",
    "    metrics = compute_performance_metrics(portfolio_df, CONFIG[\"trading_days_per_year\"])\n",
    "    monthly_pivot, yearly = monthly_and_yearly_returns(portfolio_df)\n",
    "    \n",
    "    # NEW: Compute yearly drawdowns\n",
    "    yearly_drawdowns = compute_yearly_drawdowns(portfolio_df)\n",
    "    \n",
    "    # NEW: Compute yearly risk metrics\n",
    "    yearly_risk_metrics = compute_yearly_risk_metrics(portfolio_df, CONFIG[\"trading_days_per_year\"])\n",
    "\n",
    "    summary_csv = report_root / \"performance_summary.csv\"\n",
    "    pd.DataFrame([metrics]).to_csv(summary_csv, index=False)\n",
    "\n",
    "    monthly_csv = report_root / \"monthly_returns.csv\"\n",
    "    yearly_csv = report_root / \"yearly_returns.csv\"\n",
    "    yearly_dd_csv = report_root / \"yearly_drawdowns.csv\"\n",
    "    monthly_pivot.to_csv(monthly_csv, index=True)\n",
    "    yearly.to_csv(yearly_csv, index=True)\n",
    "    yearly_drawdowns.to_csv(yearly_dd_csv, index=False)\n",
    "    # NEW: Save yearly risk metrics\n",
    "    yearly_risk_csv = report_root / \"yearly_risk_metrics.csv\"\n",
    "    yearly_risk_metrics.to_csv(yearly_risk_csv, index=False)\n",
    "\n",
    "    # Charts\n",
    "    if CONFIG[\"write_charts\"]:\n",
    "        save_equity_curve_with_trade_markers(portfolio_df, trades_df, report_root / \"equity_curve_trade_markers.png\")\n",
    "        if \"margin_used\" in daily_ledger.columns:\n",
    "            save_margin_and_free_cash(daily_ledger, report_root / \"margin_used.png\")\n",
    "\n",
    "    print(f\"Report outputs written to: {report_root.resolve()}\")\n",
    "    print(f\"- {daily_csv.name}, {daily_pq.name}\")\n",
    "    print(f\"- {trade_csv.name}\")\n",
    "    print(f\"- {rolling_vol_csv.name}, {rolling_vol_pq.name}\")\n",
    "    print(f\"- {summary_csv.name}, {monthly_csv.name}, {yearly_csv.name}, {yearly_dd_csv.name}, {yearly_risk_csv.name}\")\n",
    "    print(f\"- {summary_csv.name}, {monthly_csv.name}, {yearly_csv.name}, {yearly_dd_csv.name}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_quant_lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
