{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b635a4c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD: c:\\TWS API\\source\\pythonclient\\TradingIdeas\\Futures\n",
      "PARQUET DIR exists? False -> C:\\TWS API\\source\\pythonclient\\TradingIdeas\\Futures\\03-futures_prices_changes\\norgate_continuous\\daily_changes\\parquet\n",
      "CSV DIR exists?    False -> C:\\TWS API\\source\\pythonclient\\TradingIdeas\\Futures\\03-futures_prices_changes\\norgate_continuous\\daily_changes\\csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"CWD:\", os.getcwd())\n",
    "\n",
    "p_parq = Path(\"./03-futures_prices_changes/norgate_continuous/daily_changes/parquet\")\n",
    "p_csv  = Path(\"./03-futures_prices_changes/norgate_continuous/daily_changes/csv\")\n",
    "\n",
    "print(\"PARQUET DIR exists?\", p_parq.exists(), \"->\", p_parq.resolve())\n",
    "print(\"CSV DIR exists?   \", p_csv.exists(),  \"->\", p_csv.resolve())\n",
    "\n",
    "if p_parq.exists():\n",
    "    print(\"Parquet files:\", len(list(p_parq.glob(\"*.parquet\"))))\n",
    "    print(\"Example:\", list(p_parq.glob(\"*.parquet\"))[:5])\n",
    "\n",
    "if p_csv.exists():\n",
    "    print(\"CSV files:\", len(list(p_csv.glob(\"*.csv\"))))\n",
    "    print(\"Example:\", list(p_csv.glob(\"*.csv\"))[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08b2c718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 105 instruments.\n",
      "Done. Wrote new files to: 04-futures_price_volatility\\norgate_continuous\\volatility_measures\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\"\"\"\n",
    "===============================================================================\n",
    "ADD STANDARD DEVIATION MEASURES TO PER-INSTRUMENT CONTINUOUS FUTURES FILES\n",
    "===============================================================================\n",
    "\n",
    "Reads per-instrument files that already include:\n",
    "- daily_prices_change_pts\n",
    "- daily_prices_change_percent\n",
    "\n",
    "Computes (per instrument):\n",
    "1) daily_std_full              = std of daily returns over full dataset\n",
    "2) annualized_std_full         = daily_std_full * sqrt(TRADING_DAYS_PER_YEAR)\n",
    "3) ewma32_std                  = sqrt(EWMA(mean of r^2)) with alpha=lambda, min_periods=32\n",
    "\n",
    "Writes new per-instrument outputs:\n",
    "- CSV:    OUTPUT_ROOT/csv/<SYMBOL>.csv\n",
    "- Parquet OUTPUT_ROOT/parquet/<SYMBOL>.parquet\n",
    "\"\"\"\n",
    "\n",
    "# ============================================================\n",
    "# Configuration\n",
    "# ============================================================\n",
    "\n",
    "# Input folders (these should point to the outputs you created after adding daily changes)\n",
    "# Adjust to match your actual folder names.\n",
    "INPUT_PARQUET_DIR = Path(\"./03-futures_price_changes/norgate_continuous/daily_changes/parquet\")\n",
    "INPUT_CSV_DIR     = Path(\"./03-futures_price_changes/norgate_continuous/daily_changes/csv\")\n",
    "PREFER_PARQUET_INPUT = True\n",
    "\n",
    "# Output folders (new set of files; does not overwrite input)\n",
    "OUTPUT_ROOT = Path(\"./04-futures_price_volatility/norgate_continuous/volatility_measures\")\n",
    "OUTPUT_CSV_DIR = OUTPUT_ROOT / \"csv\"\n",
    "OUTPUT_PARQUET_DIR = OUTPUT_ROOT / \"parquet\"\n",
    "\n",
    "# Trading days for annualization\n",
    "TRADING_DAYS_PER_YEAR = 256\n",
    "\n",
    "# EWMA settings\n",
    "EWMA_MIN_PERIODS = 32\n",
    "EWMA_LAMBDA = 0.06061  # smoothing factor alpha in pandas ewm(alpha=...)\n",
    "\n",
    "# Required columns (canonical names we will enforce)\n",
    "DATE_COL = \"date\"\n",
    "RET_COL  = \"daily_prices_change_percent\"\n",
    "\n",
    "# Optional column aliases to harmonize common variants\n",
    "COL_ALIASES = {\n",
    "    \"delivery month\": [\"delivery month\", \"delivery_month\", \"deliverymonth\", \"contract_month\", \"delivery\"],\n",
    "    \"open interest\":  [\"open interest\", \"open_interest\", \"openinterest\", \"oi\"],\n",
    "}\n",
    "\n",
    "# New columns to add\n",
    "NEW_COLS = [\"daily_std_full\", \"annualized_std_full\", \"ewma32_std\"]\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Implementation\n",
    "# ============================================================\n",
    "\n",
    "def ensure_dirs() -> None:\n",
    "    OUTPUT_CSV_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    OUTPUT_PARQUET_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def normalize_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df.columns = [str(c).strip().lower() for c in df.columns]\n",
    "    return df\n",
    "\n",
    "def ensure_date_column(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # If date is index, bring it back as a column\n",
    "    if isinstance(df.index, pd.DatetimeIndex) and (DATE_COL not in df.columns):\n",
    "        df = df.reset_index()\n",
    "\n",
    "    if DATE_COL not in df.columns:\n",
    "        raise ValueError(f\"Missing '{DATE_COL}' column. Found: {list(df.columns)}\")\n",
    "\n",
    "    df[DATE_COL] = pd.to_datetime(df[DATE_COL], errors=\"coerce\")\n",
    "    df = df.dropna(subset=[DATE_COL]).sort_values(DATE_COL)\n",
    "    return df\n",
    "\n",
    "def harmonize_optional_cols(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Ensure canonical optional columns exist (even if NaN)\n",
    "    for canonical, aliases in COL_ALIASES.items():\n",
    "        found = None\n",
    "        for a in aliases:\n",
    "            a = a.lower()\n",
    "            if a in df.columns:\n",
    "                found = a\n",
    "                break\n",
    "        if found is None:\n",
    "            df[canonical] = np.nan\n",
    "        elif found != canonical:\n",
    "            df = df.rename(columns={found: canonical})\n",
    "    return df\n",
    "\n",
    "def add_vol_measures(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    if RET_COL not in df.columns:\n",
    "        raise ValueError(\n",
    "            f\"Missing '{RET_COL}' column. \"\n",
    "            f\"Ensure you ran the daily change script first. Found: {list(df.columns)}\"\n",
    "        )\n",
    "\n",
    "    r = pd.to_numeric(df[RET_COL], errors=\"coerce\")\n",
    "\n",
    "    # 1) Daily std over full dataset (ignore NaNs)\n",
    "    daily_std_full = float(r.std(ddof=1)) if r.notna().sum() >= 2 else np.nan\n",
    "\n",
    "    # 2) Annualized std (256 trading days)\n",
    "    annualized_std_full = float(daily_std_full * np.sqrt(TRADING_DAYS_PER_YEAR)) if pd.notna(daily_std_full) else np.nan\n",
    "\n",
    "    # 3) EWMA(32) std from squared returns; start after 32 observations\n",
    "    # Using ewm mean on r^2, then sqrt -> std\n",
    "    r2 = r ** 2\n",
    "    ewma_var = r2.ewm(alpha=EWMA_LAMBDA, adjust=False, min_periods=EWMA_MIN_PERIODS).mean()\n",
    "    ewma32_std = np.sqrt(ewma_var)\n",
    "\n",
    "    df[\"daily_std_full\"] = daily_std_full\n",
    "    df[\"annualized_std_full\"] = annualized_std_full\n",
    "    df[\"ewma32_std\"] = ewma32_std\n",
    "\n",
    "    return df\n",
    "\n",
    "def reorder_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    base = [\n",
    "        \"date\", \"open\", \"high\", \"low\", \"close\", \"volume\",\n",
    "        \"delivery month\", \"open interest\",\n",
    "        \"daily_prices_change_pts\", \"daily_prices_change_percent\",\n",
    "        \"daily_std_full\", \"annualized_std_full\", \"ewma32_std\",\n",
    "    ]\n",
    "    present_base = [c for c in base if c in df.columns]\n",
    "    remaining = [c for c in df.columns if c not in present_base]\n",
    "    return df[present_base + remaining]\n",
    "\n",
    "def read_symbol(sym: str) -> pd.DataFrame:\n",
    "    pq = INPUT_PARQUET_DIR / f\"{sym}.parquet\"\n",
    "    csv = INPUT_CSV_DIR / f\"{sym}.csv\"\n",
    "\n",
    "    if PREFER_PARQUET_INPUT and pq.exists():\n",
    "        df = pd.read_parquet(pq)\n",
    "    elif csv.exists():\n",
    "        df = pd.read_csv(csv)\n",
    "    elif pq.exists():\n",
    "        df = pd.read_parquet(pq)\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"No input found for {sym} in {INPUT_PARQUET_DIR} or {INPUT_CSV_DIR}\")\n",
    "\n",
    "    df = normalize_columns(df)\n",
    "    df = ensure_date_column(df)\n",
    "    df = harmonize_optional_cols(df)\n",
    "    return df\n",
    "\n",
    "def write_symbol(sym: str, df: pd.DataFrame) -> None:\n",
    "    out_csv = OUTPUT_CSV_DIR / f\"{sym}.csv\"\n",
    "    out_pq  = OUTPUT_PARQUET_DIR / f\"{sym}.parquet\"\n",
    "    df.to_csv(out_csv, index=False)\n",
    "    df.to_parquet(out_pq, index=False, compression=\"snappy\")\n",
    "\n",
    "def main() -> None:\n",
    "    ensure_dirs()\n",
    "\n",
    "    syms = set()\n",
    "    if INPUT_PARQUET_DIR.exists():\n",
    "        syms |= {p.stem for p in INPUT_PARQUET_DIR.glob(\"*.parquet\")}\n",
    "    if INPUT_CSV_DIR.exists():\n",
    "        syms |= {p.stem for p in INPUT_CSV_DIR.glob(\"*.csv\")}\n",
    "\n",
    "    if not syms:\n",
    "        raise RuntimeError(\n",
    "            f\"No per-instrument files found.\\n\"\n",
    "            f\"Checked:\\n- {INPUT_PARQUET_DIR}\\n- {INPUT_CSV_DIR}\"\n",
    "        )\n",
    "\n",
    "    print(f\"Found {len(syms)} instruments.\")\n",
    "    for sym in sorted(syms):\n",
    "        df = read_symbol(sym)\n",
    "        df = add_vol_measures(df)\n",
    "        df = reorder_columns(df)\n",
    "        write_symbol(sym, df)\n",
    "\n",
    "    print(f\"Done. Wrote new files to: {OUTPUT_ROOT}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_quant_lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
